<reasoning>I need to carefully extract information from this job posting following the strict rules. Let me go through each section systematically.

Looking at the job posting:

Title: Data Engineer-Data Platforms-Azure
Company: IBM
Location: Kochi, Kerala, India

Description:
Introduction In this role, you&apos;ll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology. Your Role And Responsibilities As an Associate Software Developer at IBM you will harness the power of data to unveil captivating stories and intricate patterns. You&apos;ll contribute to data gathering, storage, and both batch and real-time processing. Collaborating closely with diverse teams, you&apos;ll play an important role in deciding the most suitable data management systems and identifying the crucial data required for insightful analysis. As a Data Engineer, you&apos;ll tackle obstacles related to database integration and untangle complex, unstructured data sets. In this role, your responsibilities may include: Implementing and validating predictive models as well as creating and maintain statistical models with a focus on big data, incorporating a variety of statistical and machine learning techniques Designing and implementing various enterprise search applications such as Elasticsearch and Splunk for client requirements Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors. Required Technical And Professional Expertise Total Exp-6-7 Yrs (Relevant-4-5 Yrs) Mandatory Skills: Azure Databricks, Python/PySpark, SQL, Github, - Azure Devops - Azure Blob Ability to use programming languages like Java, Python, Scala, etc., to build pipelines to extract and transform data from a repository to a data consumer Ability to use Extract, Transform, and Load (ETL) tools and/or data integration, or federation tools to prepare and transform data as needed. 

I'll focus on the technical skills and experience requirements for this role. The position demands expertise in multiple programming languages and data processing technologies. Candidates need strong programming abilities in Java, Python, and Scala, with experience in data pipeline development. The role requires proficiency in ETL tools, data integration, and working with various data transformation techniques. Key technologies include Azure Databricks, PySpark, SQL, and GitHub, indicating a cloud-based, collaborative data engineering environment.

The soft skills emphasize communication and teamwork. Candidates must demonstrate excellent verbal and written communication, with the ability to interact effectively with both internal and external stakeholders. The role involves translating complex technical concepts into clear, actionable insights for diverse audiences, requiring strong analytical and presentation capabilities.

The position is based in Kochi, Kerala, India, with no explicit remote work options mentioned. It appears to be a full-time role, though specific employment type details are not clearly defined. The job description suggests a collaborative, client-focused environment that values cross-functional communication and technical expertise.

The role involves data engineering and software development, with a focus on predictive modeling, statistical analysis, and data processing. Key technical requirements include experience with Azure Databricks, Python/PySpark, SQL, and various data integration tools. The position emphasizes working in agile, cross-functional teams to solve complex data challenges.

The soft skills highlight strong communication abilities, both verbal and written, with the capacity to interact effectively with diverse stakeholders. The role demands translating technical insights for both technical and non-technical audiences, indicating a need for versatile communication skills.

The position requires 6-7 years of total experience, with 4-5 years of relevant expertise. No specific educational requirements are mentioned, and the role does not explicitly reference advanced AI technologies like LLMs or feature stores.

The work model indicates an onsite position in Kochi, Kerala, India, with a full-time employment type. No specific contract details are provided, suggesting a standard permanent employment arrangement.

The compensation section reveals no disclosed salary information, with no minimum or maximum pay rates specified. No additional financial details like hourly rates or contractor compensation are mentioned.

Work authorization requirements are not explicitly defined, leaving the visa sponsorship status unclear. The posting lacks specific details about work eligibility or citizenship requirements.

Geographic restrictions appear limited to the Kochi location, with no apparent global or regional constraints. The role seems focused on local talent within the specific Indian city.

Benefits are minimally described, with no concrete details about equity, learning opportunities, or time-off policies. The posting provides a high-level overview without diving into comprehensive compensation or benefit specifics.

The company context highlights IBM's consulting approach, emphasizing technical expertise across public and private sectors through specialized delivery centers. These centers aim to provide locally-based technical skills that drive innovation and technology adoption.

The role involves complex data engineering challenges, requiring expertise in predictive modeling, statistical analysis, and data processing across diverse technological environments. Key responsibilities include designing enterprise search applications, working in agile teams, and solving intricate data integration problems.

Technical requirements emphasize strong programming capabilities in Python, Java, and Scala, with specific experience in Azure Databricks, PySpark, SQL, and GitHub. The position demands proficiency in ETL tools, data transformation, and working with big data technologies like Spark and Hadoop.

Soft skills focus on exceptional communication abilities, enabling effective interaction with both internal and external stakeholders. The role requires translating technical insights for diverse audiences, highlighting the importance of clear, adaptable communication strategies.

The position requires 6-7 years of total professional experience, with 4-5 years directly relevant to the role's technical demands. No specific educational credentials are mandated, maintaining flexibility in candidate selection.

The work environment emphasizes collaborative, agile methodologies, suggesting a dynamic team-based approach to problem-solving and project execution.

Geographically, the role is centered in Kochi, Kerala, India, with no explicit remote work options indicated. The employment structure appears to be a permanent, full-time position, though specific contract details remain unspecified.

Compensation and work authorization details are not disclosed, leaving potential candidates to seek additional information through direct inquiry.

The role involves complex data engineering challenges, requiring expertise in predictive modeling, statistical analysis, and data processing across diverse technological platforms. Key responsibilities include designing enterprise search applications, working in agile teams, and solving intricate data integration problems.

Technical requirements emphasize strong programming capabilities in Python, Java, and Scala, with specific experience in Azure Databricks, PySpark, SQL, and GitHub. The position demands proficiency in ETL tools, data transformation, and working with big data technologies like Spark and Hadoop.

Soft skills focus on exceptional communication abilities, enabling effective interaction with both internal and external stakeholders. The role requires translating technical insights for diverse audiences, highlighting the importance of clear, adaptable communication strategies.

The position requires 6-7 years of total professional experience, with 4-5 years directly relevant to the role's technical demands. No specific educational credentials are mandated, maintaining flexibility in candidate selection.

The work environment emphasizes collaborative, agile methodologies, suggesting a dynamic team-based approach to problem-solving and project execution.

Geographically, the role is centered in Kochi, Kerala, India, with no explicit remote work options indicated. The employment structure appears to be a permanent, full-time position, though specific contract details remain unspecified.

Compensation and work authorization details are not disclosed, leaving potential candidates to seek additional information through direct inquiry.
</reasoning>

```json
{
  "extraction": {
    "compensation": {
      "salary_disclosed": false,
      "salary_min": null,
      "salary_max": null,
      "salary_currency": null,
      "salary_period": null,
      "salary_text_raw": null,
      "hourly_rate_min": null,
      "hourly_rate_max": null,
      "hourly_rate_currency": null,
      "hourly_rate_text_raw": null
    },
    "work_authorization": {
      "visa_sponsorship_stated": "not_mentioned",
      "work_auth_text": null,
      "citizenship_text": null,
      "security_clearance_stated": "not_mentioned"
    },
    "work_model": {
      "work_model_stated": "onsite",
      "location_restriction_text": "Kochi, Kerala, India",
      "employment_type_stated": "full_time"
    },
    "contract_details": {
      "contract_type": "permanent",
      "contract_duration_months": null,
      "contract_duration_text": null,
      "extension_possible": "not_mentioned",
      "conversion_to_fte": "not_mentioned",
      "start_date": "not_mentioned",
      "start_date_text": null,
      "probation_period_text": null
    },
    "contractor_rates": {
      "pay_type": "not_mentioned",
      "daily_rate_min": null,
      "daily_rate_max": null,
      "daily_rate_currency": null,
      "daily_rate_text_raw": null,
      "rate_negotiable": "not_mentioned",
      "overtime_paid": "not_mentioned"
    },
    "skills_classified": {
      "must_have_hard_skills": [
        "Azure Databricks",
        "Python",
        "PySpark",
        "SQL",
        "GitHub",
        "Azure DevOps",
        "Azure Blob",
        "Java",
        "Scala",
        "ETL",
        "data integration",
        "Linux",
        "Spark",
        "Hadoop"
      ],
      "nice_to_have_hard_skills": [],
      "must_have_soft_skills": [
        "Communication",
        "Team Collaboration"
      ],
      "nice_to_have_soft_skills": [],
      "certifications_mentioned": [],
      "years_experience_min": 6,
      "years_experience_max": 7,
      "years_experience_text": "Total Exp-6-7 Yrs (Relevant-4-5 Yrs)",
      "education_level": null,
      "education_area": null,
      "education_requirement": "not_mentioned",
      "education_text_raw": null,
      "llm_genai_mentioned": false,
      "feature_store_mentioned": false
    },
    "geographic_restrictions": {
      "geo_restriction_type": "specific_countries",
      "allowed_countries": ["IN"],
      "excluded_countries": [],
      "us_state_restrictions": [],
      "residency_requirement": "not_mentioned"
    },
    "benefits_structured": {
      "benefits_mentioned": [],
      "equity_mentioned": false,
      "learning_budget_mentioned": false,
      "conference_budget_mentioned": false,
      "hardware_choice_mentioned": false,
      "pto_policy": "not_mentioned"
    },
    "context": {
      "team_info_text": "Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines",
      "company_description_text": "In this role, you&apos;ll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology."
    }
  },
  "metadata": {
    "extraction_complete": true,
    "fields_found": 47,
    "fields_null": 25
  }
}
```