```json
{
  "extraction": {
    "compensation": {
      "salary_disclosed": false,
      "salary_min": null,
      "salary_max": null,
      "salary_currency": null,
      "salary_period": null,
      "salary_text_raw": null,
      "hourly_rate_min": null,
      "hourly_rate_max": null,
      "hourly_rate_currency": null,
      "hourly_rate_text_raw": null
    },
    "work_authorization": {
      "visa_sponsorship_stated": "not_mentioned",
      "work_auth_text": null,
      "citizenship_text": null,
      "security_clearance_stated": "not_mentioned"
    },
    "work_model": {
      "work_model_stated": "not_mentioned",
      "location_restriction_text": null,
      "employment_type_stated": "full_time"
    },
    "contract_details": {
      "contract_type": "not_mentioned",
      "contract_duration_months": null,
      "contract_duration_text": null,
      "extension_possible": "not_mentioned",
      "conversion_to_fte": "not_mentioned",
      "start_date": "not_mentioned",
      "start_date_text": null,
      "probation_period_text": null
    },
    "contractor_rates": {
      "pay_type": "not_mentioned",
      "daily_rate_min": null,
      "daily_rate_max": null,
      "daily_rate_currency": null,
      "daily_rate_text_raw": null,
      "rate_negotiable": "not_mentioned",
      "overtime_paid": "not_mentioned"
    },
    "skills_classified": {
      "must_have_hard_skills": ["Databricks Unified Data Analytics Platform", "Py Spark", "Spark", "Python"],
      "nice_to_have_hard_skills": ["AWS", "Azure", "GCP", "S3", "Blob Storage", "Big Query", "Redshift", "Apache Airflow", "Kafka", "DBT (Data Build Tool)", "Informatica", "Talend", "Matillion"],
      "must_have_soft_skills": ["troubleshooting", "debugging", "performance optimization"],
      "nice_to_have_soft_skills": [],
      "certifications_mentioned": [],
      "years_experience_min": 5,
      "years_experience_max": null,
      "years_experience_text": "Minimum 5 Year(s) Of Experience Is Required",
      "education_level": null,
      "education_area": null,
      "education_requirement": "required",
      "education_text_raw": "15 years full time education is required",
      "llm_genai_mentioned": false,
      "feature_store_mentioned": false
    },
    "geographic_restrictions": {
      "geo_restriction_type": "not_mentioned",
      "allowed_countries": [],
      "excluded_countries": [],
      "us_state_restrictions": [],
      "residency_requirement": "not_mentioned"
    },
    "benefits_structured": {
      "benefits_mentioned": [],
      "equity_mentioned": false,
      "learning_budget_mentioned": false,
      "conference_budget_mentioned": false,
      "hardware_choice_mentioned": false,
      "pto_policy": "not_mentioned"
    },
    "context": {
      "team_info_text": "Work as part of the data engineering team to build, maintain, and optimize scalable data pipelines for large-scale data processing. Collaborate with data scientists, analysts, and other engineers to ensure data accuracy and availability.",
      "company_description_text": null
    }
  },
  "metadata": {
    "extraction_complete": true,
    "fields_found": 10,
    "fields_null": 26
  }
}
```