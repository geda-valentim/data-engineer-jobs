<reasoning>Let me analyze the job posting and Pass 1 extraction results to infer the job characteristics according to the rules provided.

First, let me understand what we have:

**Original Job Posting:**
- Title: Data Engineer-Data Warehouse
- Company: IBM
- Location: Kochi, Kerala, India
- Role involves data gathering, storage, batch and real-time processing
- Required: DBT, ETL DataStage, Snowflake (preferred), Java, Python, Scala, Linux, SQL, Spark, Hadoop
- Nice to have: DataStage, Snowflake, Elasticsearch, Splunk
- Work model: Onsite (from Pass 1)
- Location restriction: India only (from Pass 1)

**Pass 1 Extraction:**
- Work model: onsite
- Location restriction: specific_countries, allowed_countries: ["IN"]
- Must have skills: DBT, Java, Python, Scala, ETL, Linux, SQL, Spark, Hadoop
- Nice to have skills: DataStage, Snowflake, Elasticsearch, Splunk
- No salary, benefits, visa sponsorship mentioned
- No years of experience mentioned
- No education requirements mentioned

Now let me infer each field:

**1. Seniority and Role:**
- **seniority_level**: The title is "Data Engineer-Data Warehouse" without any seniority indicator like "Senior", "Junior", etc. No years of experience mentioned. The skills required are fairly standard for data engineering (DBT, Python, SQL, Spark, etc.). This suggests a mid-level position. Confidence would be moderate since no explicit seniority indicator. Let me say "mid" with confidence 0.6.

- **job_family**: Title clearly states "Data Engineer", and the role focuses on data pipelines, ETL, data warehouse work. This is clearly "data_engineer". Confidence 0.9+.

- **sub_specialty**: The role mentions both "batch and real-time processing", and tools like DBT (batch-oriented), Spark (can do both), Hadoop (batch), and mentions data warehouse. This suggests a focus on batch ETL with some real-time capabilities. 

I'll categorize this as "batch_etl" with a hybrid processing approach. The role involves comprehensive data processing, covering both batch and real-time scenarios. The technical stack supports multiple processing paradigms, indicating a versatile data engineering approach.

- **leadership_expectation**: The role description doesn't mention any leadership responsibilities, mentoring, or team management. It's focused on individual contributor work. This suggests "ic" (individual contributor) with high confidence.

**2. Stack and Cloud:**
- **primary_cloud**: No specific cloud provider mentioned in the job posting. The tools mentioned (Spark, Hadoop, DBT, Snowflake) are cloud-agnostic or can run on multiple clouds. No AWS, Azure, or GCP specifically mentioned. This should be "not_mentioned" with high confidence.

- **secondary_clouds**: Since no primary cloud is mentioned, secondary clouds would also be empty array.

- **processing_paradigm**: The job explicitly mentions "both batch and real-time processing". This clearly indicates "hybrid" with high confidence.

- **orchestrator_category**: No specific orchestration tool mentioned. DBT is mentioned which has some orchestration capabilities, but no specific orchestrator like Airflow, Step Functions, etc. This should be "not_mentioned".

- **storage_layer**: Mentions "Data Warehouse" in the title, and Snowflake is mentioned as preferred. Snowflake is a data warehouse. Also mentions Hadoop which is more data lake oriented. This suggests "mixed" - both warehouse and lake patterns.

**3. Geo and Work Model:**
- **remote_restriction**: Pass 1 shows "specific_countries" with "IN" (India) only. This means "same_country" with high confidence.

- **timezone_focus**: Location is Kochi, Kerala, India. This suggests "specific_country" (India) with high confidence.

- **relocation_required**: The job is already located in Kochi, India, and restricts to India only. This suggests people need to already be in India or willing to relocate to India. Since it's onsite and location-specific, relocation would likely be required for non-India residents. But for India residents, no relocation needed. The restriction is geographic, not necessarily relocation. Let me think about this more carefully.

The role requires working onsite in Kochi, India, and only allows candidates from India. For someone already in India, no relocation is needed. For someone outside India, they would need to relocate. Since the restriction is "same_country" (India only), this implies that candidates should already be in India or be willing to relocate there. The more accurate interpretation is that relocation would be required for non-India residents, but the job doesn't explicitly state this. Given the location restriction, I'll infer that relocation is likely required for non-local candidates, so "true" with moderate confidence.

**4. Visa and Authorization:**
- **h1b_friendly**: Pass 1 shows "not_mentioned" for visa sponsorship. No mention of H1B or any visa sponsorship. Since this is an India-based role, H1B (US visa) wouldn't be relevant anyway. The role is in India, so this should be "false" with high confidence since it's not applicable.

- **opt_cpt_friendly**: Similar to H1B, this is about US student visas. Since the role is in India, this wouldn't be applicable. Should be "false" with high confidence.

- **citizenship_required**: No specific citizenship requirements mentioned. The role is in India and restricts to India only, but doesn't specify citizenship. Could be Indian citizens or work-authorized individuals in India. This should be "work_auth_only" with moderate confidence.

**5. Contract and Compensation:**
- **w2_vs_1099**: No specific contract type mentioned. This is a full-time role at IBM (implied), so likely "w2" (employee) but not explicitly stated. Should be "not_mentioned" with moderate confidence.

- **benefits_level**: Pass 1 shows no benefits mentioned. Should be "none_mentioned" with high confidence.

**6. Career Development:**
- **growth_path_clarity**: No mention of career paths, growth opportunities, or advancement. Should be "not_mentioned" with high confidence.

- **mentorship_signals**: Mentions working in "collaborative environment" with "other scientists, engineers, consultants and database administrators". This suggests working with others but doesn't specifically mention mentorship. This could be "implied" since collaborative environments often involve learning from others, but it's not explicit. Let me go with "implied" with moderate confidence.

- **promotion_path_mentioned**: No mention of promotion, advancement, or career growth. Should be "false" with high confidence.

- **internal_mobility_mentioned**: No mention of internal transfers, role changes, or mobility. Should be "false" with high confidence.

- **career_tracks_available**: No mention of different career tracks (IC, management, etc.). Should be empty array with high confidence.

**7. Requirements Classification:**
- **requirement_strictness**: The job has a clear distinction between "Required Technical And Professional Expertise" and "Preferred Technical And Professional Experience". The required section has specific technical skills, while preferred has additional nice-to-haves. This suggests "medium" strictness - clear requirements but also preferences. Confidence moderate.

- **scope_definition**: The role is clearly defined as "Data Engineer-Data Warehouse" with specific responsibilities around data pipelines, ETL, and data processing. This is a focused role, not a multi-role hybrid. Should be "clear" with high confidence.

- **skill_inflation_detected**: The skills required (DBT, Python, SQL, Spark, etc.) are appropriate for a data engineer role. No unrealistic combinations or excessive years of experience required. Should be "false" with high confidence.

Let me compile this into the JSON format.
</reasoning>

```json
{
  "inference": {
    "seniority_and_role": {
      "seniority_level": {
        "value": "mid",
        "confidence": 0.65,
        "evidence": "Title is 'Data Engineer-Data Warehouse' without seniority indicator, standard data engineering skills required, no years of experience specified",
        "source": "inferred"
      },
      "job_family": {
        "value": "data_engineer",
        "confidence": 0.95,
        "evidence": "Title explicitly states 'Data Engineer', role focuses on data pipelines, ETL, data warehouse work, and data processing",
        "source": "pass1_derived"
      },
      "sub_specialty": {
        "value": "batch_etl",
        "confidence": 0.75,
        "evidence": "Mentions both batch and real-time processing, DBT for batch pipelines, Hadoop/Spark for batch processing, data warehouse focus",
        "source": "inferred"
      },
      "leadership_expectation": {
        "value": "ic",
        "confidence": 0.85,
        "evidence": "No mention of leadership responsibilities, mentoring, or team management - focused on individual contributor technical work",
        "source": "inferred"
      }
    },
    "stack_and_cloud": {
      "primary_cloud": {
        "value": "not_mentioned",
        "confidence": 0.90,
        "evidence": "No specific cloud provider mentioned, tools mentioned (Spark, Hadoop, DBT, Snowflake) are cloud-agnostic",
        "source": "pass1_derived"
      },
      "secondary_clouds": {
        "value": [],
        "confidence": 0.90,
        "evidence": "No cloud providers mentioned at all",
        "source": "pass1_derived"
      },
      "processing_paradigm": {
        "value": "hybrid",
        "confidence": 0.90,
        "evidence": "Job explicitly mentions 'both batch and real-time processing'",
        "source": "pass1_derived"
      },
      "orchestrator_category": {
        "value": "not_mentioned",
        "confidence": 0.85,
        "evidence": "No specific orchestration tool mentioned, DBT mentioned but no orchestrator like Airflow or Step Functions",
        "source": "inferred"
      },
      "storage_layer": {
        "value": "mixed",
        "confidence": 0.75,
        "evidence": "Title mentions 'Data Warehouse', Snowflake preferred (warehouse), Hadoop mentioned (lake), suggests both patterns",
        "source": "inferred"
      }
    },
    "geo_and_work_model": {
      "remote_restriction": {
        "value": "same_country",
        "confidence": 0.90,
        "evidence": "Pass 1 shows specific_countries restriction with only 'IN' allowed, onsite work model",
        "source": "pass1_derived"
      },
      "timezone_focus": {
        "value": "specific_country",
        "confidence": 0.90,
        "evidence": "Location is Kochi, Kerala, India with country restriction to India only",
        "source": "pass1_derived"
      },
      "relocation_required": {
        "value": true,
        "confidence": 0.70,
        "evidence": "Onsite role in Kochi, India with India-only restriction implies relocation needed for non-India residents",
        "source": "inferred"
      }
    },
    "visa_and_authorization": {
      "h1b_friendly": {
        "value": false,
        "confidence": 0.90,
        "evidence": "India-based role, no visa sponsorship mentioned, H1B not applicable for Indian positions",
        "source": "pass1_derived"
      },
      "opt_cpt_friendly": {
        "value": false,
        "confidence": 0.90,
        "evidence": "India-based role, OPT/CPT are US student visa programs not applicable to Indian positions",
        "source": "pass1_derived"
      },
      "citizenship_required": {
        "value": "work_auth_only",
        "confidence": 0.70,
        "evidence": "No citizenship requirement specified, India location suggests work authorization in India is required",
        "source": "inferred"
      }
    },
    "contract_and_compensation": {
      "w2_vs_1099": {
        "value": "not_mentioned",
        "confidence": 0.75,
        "evidence": "No contract type specified, appears to be full-time IBM position but employment type not explicitly stated",
        "source": "inferred"
      },
      "benefits_level": {
        "value": "none_mentioned",
        "confidence": 0.95,
        "evidence": "Pass 1 shows no benefits mentioned in job posting",
        "source": "pass1_derived"
      }
    },
    "career_development": {
      "growth_path_clarity": {
        "value": "not_mentioned",
        "confidence": 0.90,
        "evidence": "No mention of career paths, growth opportunities, or advancement potential",
        "source": "pass1_derived"
      },
      "mentorship_signals": {
        "value": "implied",
        "confidence": 0.65,
        "evidence": "Mentions collaborative environment with scientists, engineers, consultants - suggests working with experienced professionals",
        "source": "inferred"
      },
      "promotion_path_mentioned": {
        "value": false,
        "confidence": 0.90,
        "evidence": "No mention of promotion, advancement, or career growth opportunities",
        "source": "pass1_derived"
      },
      "internal_mobility_mentioned": {
        "value": false,
        "confidence": 0.90,
        "evidence": "No mention of internal transfers, role changes, or mobility opportunities",
        "source": "pass1_derived"
      },
      "career_tracks_available": {
        "value": [],
        "confidence": 0.90,
        "evidence": "No mention of different career tracks (IC, management, specialist, architect paths)",
        "source": "pass1_derived"
      }
    },
    "requirements_classification": {
      "requirement_strictness": {
        "value": "medium",
        "confidence": 0.75,
        "evidence": "Clear distinction between required skills (DBT, Python, SQL, etc.) and preferred skills (DataStage, Snowflake, etc.)",
        "source": "inferred"
      },
      "scope_definition": {
        "value": "clear",
        "confidence": 0.85,
        "evidence": "Focused role as 'Data Engineer-Data Warehouse' with specific responsibilities around data pipelines and processing",
        "source": "inferred"
      },
      "skill_inflation_detected": {
        "value": false,
        "confidence": 0.85,
        "evidence": "Skills required (DBT, Python, SQL, Spark, etc.) are appropriate and realistic for data engineer role, no excessive requirements",
        "source": "inferred"
      }
    }
  }
}
```